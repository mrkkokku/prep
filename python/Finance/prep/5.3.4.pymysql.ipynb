{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymysql을 이용하면 파이썬에서 SQL을 직접 수행할 수 있다\n",
    "\n",
    "# 다음은 매일 일정한 시간에 네이버 금융 데이터를 스크랩해서 MariaDB에 업데이트하는 DBUpdater 클래스다\n",
    "\n",
    "# 여기 클래스로 이름붙은 애들 잘 보자, 얘들은 전부 클래스이름별로 각 파일로 빠져나가야할 애들이다\n",
    "# 지금 작성하는 이 주피터는 그냥 공부용 책으로 생각하면 된다.\n",
    "# 작성 내용은 책과 동일하게 맞출 것이고, 실제 DB CRUD내용은 커스텀해서 파일로 만들어나가자\n",
    "\n",
    "# 여기를 실행시키려면 cmd에서 python ~/DBUpdater.py 하면 되고, 테이블 확인은 MariaDB에서 직접 조회하자\n",
    "\n",
    "# 참고로 아래의 클래스 함수들은 책에서 소개한 순서대로 작성한 것이며\n",
    "# 순차적으로 읽어나가면 된다\n",
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "class DBUpdater:\n",
    "    def __init__(self): # 2. MariaDB와 연결되는 생성자 부분\n",
    "        \"\"\"생성자: MariaDB 연결 및 종목코드 딕셔너리 생성\"\"\" # charset utf8로 해주는건 컬럼에 한글 들어갈 때 오류를 피하기 위함\n",
    "        self.conn = pymysql.connect(host='localhost', port=3306, db='Investar', user='root', passwd='@@@@@@@', charset='utf8')\n",
    "\n",
    "        with self.conn.cursor() as curs:\n",
    "            sql = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS COMPANY_INFO\n",
    "            (\n",
    "                CODE VARCHAR(20),\n",
    "                COMPANY VARCHAR(20),\n",
    "                LAST_UPDATE DATE,\n",
    "                PRIMARY KEY (CODE)\n",
    "            )\n",
    "            \"\"\"\n",
    "            curs.execute(sql)\n",
    "\n",
    "\n",
    "            sql = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS DAILY_PRICE\n",
    "            (\n",
    "                CODE VARCHAR(20),\n",
    "                DATE DATE\n",
    "                OPEN BIGINT(20),\n",
    "                HIGH BITINT(20),\n",
    "                LOW BIGINT(20),\n",
    "                CLOSE BIGINT(20),\n",
    "                DIFF BIGINT(20),\n",
    "                VOLUME BIGINT(20),\n",
    "                PRIMARY KEY (CODE, DATE)\n",
    "            )\n",
    "            \"\"\"\n",
    "            curs.execute(sql)\n",
    "\n",
    "        self.conn.commit()\n",
    "\n",
    "        self.codes = dict()\n",
    "        self.update_comp_info() # KRX 주식 코드를 읽어와서 COMPANY_INFO 테이블에 업데이트하는 것\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"소멸자: MariaDB 연결 해제\"\"\"\n",
    "        self.conn.close()\n",
    "    \n",
    "    def red_krx_code(self): # KRX로 부터 상장법인 목록 파일을 읽어온다\n",
    "        \"\"\"KRX로 부터 상장법인 목록 파일을 읽어와서 DataFrame으로 변환\"\"\"\n",
    "\n",
    "        url = 'https://kind.krx.co.kr/corpgeneral/corpList.do?method=loadInitPage#'\n",
    "\n",
    "        # read_html로 읽어들이고\n",
    "        krx = pd.read_html(requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text)[0]\n",
    "\n",
    "        # 종목코드와 회사명 두개의 컬럼만 남긴다\n",
    "        # [[ , , , ]] 이런식으로 활용하면 원하는 컬럼을 순서대로 재구성 할 수 있다.\n",
    "        # ( []하면 Series로 출력되고 [[]] 스타일이 DataFrame으로 출력되는 방식이었던 걸로 기억한다.\n",
    "        krx = krx[['종목코드', '회사명']]\n",
    "\n",
    "        # 컬럼이름을 변경하는 함수는 다음과 같다\n",
    "        krx = krx.rename(columns={'종목코드':'CODE', '회사명':'COMPANY'})\n",
    "\n",
    "        # 종목코드 앞자리 00~ 들을 패딩해주고 총 6자리로 맞춤\n",
    "        krx.code = krx.code.map('{:06d}'.format)\n",
    "\n",
    "        return krx\n",
    "    \n",
    "    def update_comp_info(self):\n",
    "        \"\"\"종목코드를 company_info 테이블에 업데이트한 후 딕셔너리에 저장\"\"\"\n",
    "        \n",
    "        sql =  \"SELECT * FROM COMPANY_INFO\"\n",
    "\n",
    "        df = pd.read_sql(sql, self.conn) # SQL을 일단 읽음\n",
    "\n",
    "        for idx in range(len(df)):\n",
    "            self.codes[df['CODE'].values[idx]] = df['COMPANY'].values[idx] # 위에서 읽은 내용으로 codes라는 딕셔너리에 종목과 회사이름 넣음\n",
    "        \n",
    "        with self.conn.cursor() as curs:\n",
    "            sql = \"SELECT MAX(LAST_UPDATE) FROM COMPANY_INFO\"\n",
    "            curs.execute(sql)\n",
    "            rs = curs.fetchone() # DB에서 가장 최근 업데이트 읽자를 가져온다.\n",
    "            today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "            if rs[0] == None or rs[0].strftime('%Y-%m-%d') < today: # 위에서 구한 마지막 업데이트일자가 없거나, 오늘보다 과거인 경우만 업데이트 한다.\n",
    "                krx = self.read_krx_code()\n",
    "\n",
    "                for idx in range(len(krx)):\n",
    "                    code = krx.code.values[idx]\n",
    "                    company = krx.company.values[idx]\n",
    "                    sql = f\"\"\"\n",
    "                    REPLATE INTO COMPANY_INFO\n",
    "                    (\n",
    "                        CODE,\n",
    "                        COMPANY,\n",
    "                        LAST_UPDATE\n",
    "                    )\n",
    "                    VALUES\n",
    "                    (\n",
    "                        '{code}',\n",
    "                        '{company},\n",
    "                        '{today}\n",
    "                    )\n",
    "                    \"\"\"\n",
    "                    curs.execute(sql) # REPLACE INTO를 활용해서 종목코드, 회사명, 오늘날짜 행들을 DB에 저장한다\n",
    "\n",
    "                    self.codes[code] = company # codes 딕셔너리에 키-값 쌍으로 종목코드와 회사명을 추가한다\n",
    "\n",
    "                    tmnow = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "                    print(f\"[{tmnow}] {idx:04d} REPLACE INTO COMPANY_INFO COMPANY \"\\\n",
    "                    f\"VALUES ({code}, {company}, {today}\")\n",
    "                \n",
    "                self.conn.commit()\n",
    "                print(' ')\n",
    "        \n",
    "        if __name__ == '__main__':\n",
    "            dbu = DBUpdater()   # 1. DBUpdate.py가 단독으로 실행되면 DBUpdater 객체를 생성한다\n",
    "            dbu.update_comp_info() # 3. COMPANY_INFO 테이블에 오늘 업데이트된 내용이 있는지 확인 하고\n",
    "                                    #    없으면 4를 호출하면 COMPANY_INFO 테이블을 업데이트하고 codes 딕셔너리에도 저장한다.\n",
    "            dbu.execute_daily() \n",
    "\n",
    "        \n",
    "        # 위쪽이 KRX 종목코드를 DB에 업데이트하는 부분이었다면\n",
    "        # 아래쪽은 네이버에서 스크랩하는 내용\n",
    "        # 특히 핵심은 pgRR 클래스의 <td> 태그가 없으면\n",
    "        # AttributeError 발생하면서 프로그램이 종료되니, find() 함수 결과가 None일 땐 다음 종목을 처리토록 한다\n",
    "        \n",
    "        def read_naver(self, code, company, pages_to_fetch):\n",
    "            \"\"\" 네이버에서 시세를 읽고 DataFrame으로 반환\"\"\"\n",
    "            from bs4 import BeautifulSoup\n",
    "            from urllib.request import urlopen\n",
    "            from urllib import request\n",
    "\n",
    "            import pandas as pd\n",
    "            from pandas import concat\n",
    "            import requests\n",
    "            \n",
    "            try:\n",
    "                url = f'https://finance.naver.com/item/sise_day.naver?code={code}'\n",
    "\n",
    "                html = BeautifulSoup(requests.get(url, headers={\"User-agent: Mozilla/5.0\"}).txt, \"lxml\")\n",
    "                \n",
    "                pgrr = html.find('td', class_='pgRR')\n",
    "\n",
    "                if pgrr is None:\n",
    "                    return None\n",
    "\n",
    "                s = str(pgrr.a['href']).split('=')\n",
    "                last_page = s[-1] # 네이버금융에서 시세의 마지막 페이지를 구한다\n",
    "\n",
    "                df = pd.DataFrame()\n",
    "\n",
    "                pages = min(int(last_page), pages_to_fetch) # 설정파일에서 설정된 페이지 수(pages_to_fetch)와 last_page 중 작은 것을 택함\n",
    "\n",
    "                for page in range(1, pages + 1):\n",
    "                    page_url = '{}&page={}'.format(url, page)\n",
    "                    df = pd.concat([df, pd.read_html(requests.get(page_url, headers={'User-agent': 'Mozilla/5.0'}).text)[0]])\n",
    "\n",
    "                    tmnow = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "                    print('[{}] {} ({}) : {:04d}/{:04d} pages are downloading...'.format(tmnow, company, code, page, pages), end=\"\\r\")\n",
    "\n",
    "                # 네이버 금융에서 받은 자료의 컬럼이름들을 영문으로 변환\n",
    "                df = df.rename(columns={'날짜':'date', '시가':'open', '고가':'high', '저가':'low', '종가':'close', '거래량':'volume'})\n",
    "                # 날짜 표기 형식도 변환\n",
    "                df['date'] = df['date'].replace('.', '-')\n",
    "                df = df.dropna()\n",
    "\n",
    "                # MariaDB의 BIGINT형 컬럼들에 들어갈 데이터들을 int형으로 변환 해 줌\n",
    "                df[['close','diff','open','high','low','volume']] = df[['close','diff','open','high','low','volume']].astype(int)\n",
    "\n",
    "                # 원하는 순서로 컬럼을 재조합하여 DataFrame 생성\n",
    "                df = df[['date','open','high','low','close','diff','volume']]\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(\"Exception Occured : \", str(e))\n",
    "                return None\n",
    "            \n",
    "            return df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
